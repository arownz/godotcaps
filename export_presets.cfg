[preset.0]

name="Web"
platform="Web"
runnable=true
advanced_options=true
dedicated_server=false
custom_features=""
export_filter="all_resources"
include_filter="*.env, *.js, *.worker.js, *.json, *.html, *.wasm, *.png, *.jpg, *.jpeg, *.svg, *.css, *.ttf, *.otf, *.woff, *.woff2"
exclude_filter=""
export_path="WebTest/index.html"
patches=PackedStringArray()
encryption_include_filters=""
encryption_exclude_filters=""
seed=0
encrypt_pck=true
encrypt_directory=false
script_export_mode=2

[preset.0.options]

custom_template/debug=""
custom_template/release=""
variant/extensions_support=false
variant/thread_support=false
vram_texture_compression/for_desktop=true
vram_texture_compression/for_mobile=false
html/export_icon=true
html/custom_html_shell=""
html/head_include="<!-- Custom Head Include with Cross-Origin Policies -->
<meta http-equiv=\"Cross-Origin-Opener-Policy\" content=\"same-origin\">
<meta http-equiv=\"Cross-Origin-Embedder-Policy\" content=\"require-corp\">

<script>
    // Google Cloud Vision API Configuration
    window.GOOGLE_CLOUD_API_KEY = \"AIzaSyCz9BNjDlDYDvioKMwzR2_f8D1vHseQtZ0\";

    // For challenge word debugging
    window.currentChallengeWord = \"\";
    window.setChallengeWord = function (word) {
        window.currentChallengeWord = word;
        console.log(\"Challenge word set to:\", word);
        window.debugLog(\"Challenge word set to: \" + word);
    };

    // Debug functions to test if the JavaScript bridge is working
    window.debugLog = function(message) {
        console.log(\"GODOT DEBUG:\", message);
        var debugOutput = document.getElementById('debug-output');
        if (debugOutput) {
            debugOutput.style.display = 'block';
            debugOutput.innerText += message + \"\\n\";
            debugOutput.scrollTop = debugOutput.scrollHeight;
        }
        return true;
    };
    
    window.testJavaScriptBridge = function() {
        console.log(\"JavaScript bridge test function called successfully\");
        return \"JavaScript bridge is working!\";
    };

    // Direct function for Godot to process an image through Google Cloud Vision API
    window.godotProcessImageVision = function(base64Image, width, height) {
        return new Promise(function(resolve, reject) {
            try {
                console.log(\"godotProcessImageVision called with image: \" + width + \"x\" + height);
                
                // First preprocess the image with timeout handling
                const preprocessPromise = new Promise((resolvePreprocess, rejectPreprocess) => {
                    // Set a timeout for preprocessing
                    const timeoutId = setTimeout(() => {
                        rejectPreprocess(new Error('Preprocessing timed out'));
                    }, 5000);
                    
                    window.preprocessHandwritingImage(base64Image, width, height)
                        .then(function(processedImage) {
                            clearTimeout(timeoutId);
                            resolvePreprocess(processedImage);
                        })
                        .catch(function(error) {
                            clearTimeout(timeoutId);
                            rejectPreprocess(error);
                        });
                });
                
                preprocessPromise
                    .then(function(processedImage) {
                        // Then call the Cloud Vision API with timeout handling
                        const apiPromise = new Promise((resolveApi, rejectApi) => {
                            // Set a timeout for API call
                            const timeoutId = setTimeout(() => {
                                rejectApi(new Error('API call timed out'));
                            }, 10000);
                            
                            window.callGoogleVisionApi(processedImage)
                                .then(function(result) {
                                    clearTimeout(timeoutId);
                                    console.log('Vision API result:', result);
                                    resolve(result);
                                })
                                .catch(function(error) {
                                    clearTimeout(timeoutId);
                                    console.error('Error in Vision API call:', error);
                                    resolve('recognition_error: ' + error.message);
                                });
                        });
                        
                        return apiPromise;
                    })
                    .catch(function(error) {
                        console.error('Error preprocessing image:', error);
                        resolve('recognition_error: ' + error.message);
                    });
            } catch(error) {
                console.error('Error in image processing:', error);
                resolve('recognition_error: ' + error.message);
            }
        });
    };

    // Function to preprocess images before sending to Cloud Vision API
    window.preprocessHandwritingImage = function (imageBase64, canvasWidth, canvasHeight) {
        return new Promise((resolve) => {
            try {
                console.log(\"Preprocessing image: \" + canvasWidth + \"x\" + canvasHeight);
                const img = new Image();
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d');

                // Use a smaller size for the image to reduce data size
                const maxSize = 600; // Reduced from 800
                let width = canvasWidth;
                let height = canvasHeight;

                // Resize if too large
                if (width > maxSize || height > maxSize) {
                    const ratio = width / height;
                    if (width > height) {
                        width = maxSize;
                        height = width / ratio;
                    } else {
                        height = maxSize;
                        width = height * ratio;
                    }
                }

                canvas.width = width;
                canvas.height = height;

                // Add error handling to image loading
                img.onload = function () {
                    // Draw image on white background
                    ctx.fillStyle = 'white';
                    ctx.fillRect(0, 0, canvas.width, canvas.height);
                    
                    // Draw with higher contrast
                    ctx.globalAlpha = 1.0; // Full opacity for better contrast
                    ctx.drawImage(img, 0, 0, width, height);

                    // Process the image to enhance recognition - improved algorithm
                    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                    const data = imageData.data;

                    // Enhanced thresholding for handwriting
                    for (let i = 0; i < data.length; i += 4) {
                        const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
                        // Lower threshold for better detection of light strokes
                        const value = avg < 140 ? 0 : 255;  // Changed from 160 to 140
                        data[i] = data[i + 1] = data[i + 2] = value;
                    }

                    ctx.putImageData(imageData, 0, 0);

                    // Use PNG format which is better for text
                    try {
                        const pngData = canvas.toDataURL('image/png', 1.0).split(',')[1];
                        console.log('Using PNG format for image with maximum quality');
                        resolve(pngData);
                    } catch (e) {
                        console.error('Error converting image:', e);
                        resolve(imageBase64); // Fallback to original image
                    }
                };

                img.onerror = function(e) {
                    console.error('Error loading image:', e);
                    resolve(imageBase64); // Fallback to original image
                };

                // Set crossOrigin to anonymous
                img.crossOrigin = 'Anonymous';
                img.src = 'data:image/png;base64,' + imageBase64;
            } catch(e) {
                console.error('Preprocessing error:', e);
                resolve(imageBase64); // Fallback to original image
            }
        });
    };

    // Google Cloud Vision API implementation
    window.callGoogleVisionApi = async function (base64Image) {
        try {
            console.log('Calling Google Cloud Vision API...');

            // Use the configured API key
            const apiKey = window.GOOGLE_CLOUD_API_KEY;
            if (!apiKey) {
                throw new Error(\"API key not found\");
            }
            
            const url = 'https://vision.googleapis.com/v1/images:annotate?key=' + apiKey;

            // Log image size to help with debugging
            console.log('Image size (bytes):', Math.round(base64Image.length * 0.75));

            // Prepare the request data with simpler features
            const requestData = {
                requests: [{
                    image: {
                        content: base64Image
                    },
                    features: [{
                        type: 'DOCUMENT_TEXT_DETECTION',
                        maxResults: 5
                    }],
                    imageContext: {
                        languageHints: ['en']
                    }
                }]
            };

            // Send the request with improved error handling
            console.log('Sending request to Vision API...');
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Accept': 'application/json'
                },
                body: JSON.stringify(requestData)
            });

            console.log('Response status:', response.status);

            if (!response.ok) {
                const errorText = await response.text();
                console.error('API error response:', errorText);
                throw new Error(`API request failed: ${response.status} - ${errorText}`);
            }

            const result = await response.json();
            console.log('Vision API response:', result);

            // Extract text from response - handle both annotation types
            if (result.responses && result.responses[0]) {
                // First try fullTextAnnotation
                if (result.responses[0].fullTextAnnotation) {
                    return result.responses[0].fullTextAnnotation.text.trim();
                }
                // Then try textAnnotations
                else if (result.responses[0].textAnnotations && result.responses[0].textAnnotations.length > 0) {
                    return result.responses[0].textAnnotations[0].description.trim();
                }
            }

            return 'no_text_detected';
        } catch (error) {
            console.error('Error in Vision API call:', error);
            return 'recognition_error';
        }
    };

    // Test function to verify API works - FIXED VERSION
    window.testVisionAPI = async function () {
        try {
            console.log('Testing Vision API access...');

            // Load the test image file
            const response = await fetch(\"HelloWorld.png\");
            const blob = await response.blob();
            
            // Convert to base64
            const reader = new FileReader();
            const base64Promise = new Promise(resolve => {
                reader.onloadend = () => resolve(reader.result.split(',')[1]);
                reader.readAsDataURL(blob);
            });
            const base64Image = await base64Promise;
            
            console.log('Test image loaded, size:', Math.round(base64Image.length / 1024), 'KB');
            
            // Now call the Vision API with the base64 data
            const result = await window.callGoogleVisionApi(base64Image);
            console.log('Test result:', result);
            return 'API test completed with result: ' + result;
        } catch (e) {
            console.error('API test failed:', e);
            return 'API test failed: ' + e.message;
        }
    };

    // Run API test on page load to verify connectivity
    document.addEventListener('DOMContentLoaded', function () {
        // Create debug output div
        var debugOutput = document.createElement('div');
        debugOutput.id = 'debug-output';
        debugOutput.style.display = 'none';
        debugOutput.style.position = 'fixed';
        debugOutput.style.bottom = '10px';
        debugOutput.style.right = '10px';
        debugOutput.style.width = '300px';
        debugOutput.style.height = '200px';
        debugOutput.style.backgroundColor = 'rgba(0,0,0,0.7)';
        debugOutput.style.color = 'white';
        debugOutput.style.padding = '10px';
        debugOutput.style.fontFamily = 'monospace';
        debugOutput.style.fontSize = '12px';
        debugOutput.style.overflow = 'auto';
        debugOutput.style.zIndex = '9999';
        document.body.appendChild(debugOutput);
        
        setTimeout(async function () {
            try {
                window.debugLog(\"Testing Vision API...\");
                const testResult = await window.testVisionAPI();
                window.debugLog('API test result: ' + testResult);
            } catch (error) {
                console.error('API test error:', error);
                window.debugLog('API test error: ' + error.message);
            }
        }, 2000);
    });
</script>

<script>
    // Initialize speech synthesis for TTS support
    document.addEventListener('DOMContentLoaded', function () {
        console.log('Initializing speech synthesis');

        if ('speechSynthesis' in window) {
            // Get available voices immediately
            window.speechSynthesis.getVoices();

            // Set up voice change event handler
            if (typeof speechSynthesis.onvoiceschanged !== 'undefined') {
                speechSynthesis.onvoiceschanged = function () {
                    console.log('Voices loaded:', window.speechSynthesis.getVoices().length);
                };
            }

            // Create a silent utterance to initialize the system
            const silence = new SpeechSynthesisUtterance('');
            silence.volume = 0; // Silent
            window.speechSynthesis.speak(silence);

            // Set up user interaction handler for browsers that need it
            document.addEventListener('click', function initAudio() {
                if (window.speechSynthesis) {
                    const click = new SpeechSynthesisUtterance('.');
                    click.volume = 0;
                    window.speechSynthesis.speak(click);

                    // Only need to do this once
                    document.removeEventListener('click', initAudio);
                    console.log('Speech synthesis initialized via user interaction');
                }
            });

            console.log('Speech synthesis initialized');
        }
    });
</script>"
html/canvas_resize_policy=2
html/focus_canvas_on_start=true
html/experimental_virtual_keyboard=false
progressive_web_app/enabled=true
progressive_web_app/ensure_cross_origin_isolation_headers=true
progressive_web_app/offline_page=""
progressive_web_app/display=3
progressive_web_app/orientation=0
progressive_web_app/icon_144x144=""
progressive_web_app/icon_180x180=""
progressive_web_app/icon_512x512=""
progressive_web_app/background_color=Color(0, 0, 0, 1)
");
				const blob = await response.blob();
				
				// Convert to base64
				const reader = new FileReader();
				const base64Promise = new Promise(resolve => {
					reader.onloadend = () => resolve(reader.result.split(',')[1]);
					reader.readAsDataURL(blob);
				});
				const base64Image = await base64Promise;
				
				console.log('Test image loaded, size:', Math.round(base64Image.length / 1024), 'KB');
				
				// Now call the Vision API with the base64 data
				const result = await window.callGoogleVisionApi(base64Image);
				console.log('Test result:', result);
				return 'API test completed with result: ' + result;
			} catch (e) {
				console.error('API test failed:', e);
				return 'API test failed: ' + e.message;
			}
		};

		// Run API test on page load to verify connectivity
		document.addEventListener('DOMContentLoaded', function () {
			// Create debug output div
			var debugOutput = document.createElement('div');
			debugOutput.id = 'debug-output';
			document.body.appendChild(debugOutput);
			
			setTimeout(async function () {
				try {
					window.debugLog(\"Testing Vision API...\");
					const testResult = await window.testVisionAPI();
					window.debugLog('API test result: ' + testResult);
				} catch (error) {
					console.error('API test error:', error);
					window.debugLog('API test error: ' + error.message);
				}
			}, 2000);
		});
	</script>

	<script>
		// Initialize speech synthesis for TTS support
		document.addEventListener('DOMContentLoaded', function () {
			console.log('Initializing speech synthesis');

			if ('speechSynthesis' in window) {
				// Get available voices immediately
				window.speechSynthesis.getVoices();

				// Set up voice change event handler
				if (typeof speechSynthesis.onvoiceschanged !== 'undefined') {
					speechSynthesis.onvoiceschanged = function () {
						console.log('Voices loaded:', window.speechSynthesis.getVoices().length);
					};
				}

				// Create a silent utterance to initialize the system
				const silence = new SpeechSynthesisUtterance('');
				silence.volume = 0; // Silent
				window.speechSynthesis.speak(silence);

				// Set up user interaction handler for browsers that need it
				document.addEventListener('click', function initAudio() {
					if (window.speechSynthesis) {
						const click = new SpeechSynthesisUtterance('.');
						click.volume = 0;
						window.speechSynthesis.speak(click);

						// Only need to do this once
						document.removeEventListener('click', initAudio);
						console.log('Speech synthesis initialized via user interaction');
					}
				});

				console.log('Speech synthesis initialized');
			}
		});
	</script>html/canvas_resize_policy"=2

[preset.1]

name="Windows Desktop"
platform="Windows Desktop"
runnable=true
advanced_options=false
dedicated_server=false
custom_features=""
export_filter="all_resources"
include_filter="*.env"
exclude_filter=""
export_path="StandaloneTest/index.exe"
patches=PackedStringArray()
encryption_include_filters=""
encryption_exclude_filters=""
seed=0
encrypt_pck=false
encrypt_directory=false
script_export_mode=2

[preset.1.options]

custom_template/debug=""
custom_template/release=""
debug/export_console_wrapper=1
binary_format/embed_pck=false
texture_format/s3tc_bptc=true
texture_format/etc2_astc=false
binary_format/architecture="x86_64"
codesign/enable=false
codesign/timestamp=true
codesign/timestamp_server_url=""
codesign/digest_algorithm=1
codesign/description=""
codesign/custom_options=PackedStringArray()
application/modify_resources=true
application/icon=""
application/console_wrapper_icon=""
application/icon_interpolation=4
application/file_version=""
application/product_version=""
application/company_name=""
application/product_name=""
application/file_description=""
application/copyright=""
application/trademarks=""
application/export_angle=0
application/export_d3d12=0
application/d3d12_agility_sdk_multiarch=true
ssh_remote_deploy/enabled=false
ssh_remote_deploy/host="user@host_ip"
ssh_remote_deploy/port="22"
ssh_remote_deploy/extra_args_ssh=""
ssh_remote_deploy/extra_args_scp=""
ssh_remote_deploy/run_script="Expand-Archive -LiteralPath '{temp_dir}\\{archive_name}' -DestinationPath '{temp_dir}'
$action = New-ScheduledTaskAction -Execute '{temp_dir}\\{exe_name}' -Argument '{cmd_args}'
$trigger = New-ScheduledTaskTrigger -Once -At 00:00
$settings = New-ScheduledTaskSettingsSet -AllowStartIfOnBatteries -DontStopIfGoingOnBatteries
$task = New-ScheduledTask -Action $action -Trigger $trigger -Settings $settings
Register-ScheduledTask godot_remote_debug -InputObject $task -Force:$true
Start-ScheduledTask -TaskName godot_remote_debug
while (Get-ScheduledTask -TaskName godot_remote_debug | ? State -eq running) { Start-Sleep -Milliseconds 100 }
Unregister-ScheduledTask -TaskName godot_remote_debug -Confirm:$false -ErrorAction:SilentlyContinue"
ssh_remote_deploy/cleanup_script="Stop-ScheduledTask -TaskName godot_remote_debug -ErrorAction:SilentlyContinue
Unregister-ScheduledTask -TaskName godot_remote_debug -Confirm:$false -ErrorAction:SilentlyContinue
Remove-Item -Recurse -Force '{temp_dir}'"
