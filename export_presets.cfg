[preset.0]

name="Web"
platform="Web"
runnable=true
advanced_options=true
dedicated_server=false
custom_features=""
export_filter="all_resources"
include_filter="*.env, *.js, *.worker.js, *.json, *.html, *.wasm, *.png, *.jpg, *.jpeg, *.svg, *.css, *.ttf, *.otf, *.woff, *.woff2"
exclude_filter=""
export_path="WebTest/index.html"
patches=PackedStringArray()
encryption_include_filters=""
encryption_exclude_filters=""
seed=0
encrypt_pck=true
encrypt_directory=false
script_export_mode=2

[preset.0.options]

custom_template/debug=""
custom_template/release=""
variant/extensions_support=false
variant/thread_support=true
vram_texture_compression/for_desktop=false
vram_texture_compression/for_mobile=false
html/export_icon=true
html/custom_html_shell=""
html/head_include="<meta http-equiv=\"Cross-Origin-Opener-Policy\" content=\"same-origin\">
<meta http-equiv=\"Cross-Origin-Embedder-Policy\" content=\"require-corp\">

<script>
	// ===== GLOBAL CONFIGURATION =====
	window.GOOGLE_CLOUD_API_KEY = \"AIzaSyCz9BNjDlDYDvioKMwzR2_f8D1vHseQtZ0\";
	
	// ===== STATE MANAGEMENT =====
	// Debug and logging functions
	window.debugLog = function(message) {
		console.log(\"GODOT DEBUG:\", message);
		var debugOutput = document.getElementById('debug-output');
		if (debugOutput) {
			debugOutput.style.display = 'block';
			debugOutput.innerText += message + \"\\n\";
			debugOutput.scrollTop = debugOutput.scrollHeight;
		}
		return true;
	};
	
	// Speech recognition state
	window.godot_speech = {
		mediaRecorder: null,
		audioChunks: [],
		audioStream: null,
		recording: false,
		permissionState: 'prompt',
		
		// Debug logging function
		debugLog: function(message) {
			console.log(\"Speech Debug:\", message);
			var debugOutput = document.getElementById('debug-output');
			if (debugOutput) {
				debugOutput.innerText += \"Speech: \" + message + \"\\n\";
				debugOutput.scrollTop = debugOutput.scrollHeight;
			}
		}
	};
	
	// Challenge word tracking
	window.currentChallengeWord = \"\";
	window.setChallengeWord = function(word) {
		window.currentChallengeWord = word;
		window.challengeWord = word;  // For compatibility with both versions used
		console.log(\"Challenge word set to:\", word);
		window.debugLog(\"Challenge word set to: \" + word);
	};
	
	// Text-to-Speech functionality
	window.speakText = function(text, voiceId, rate) {
		console.log(\"Speaking text:\", text);
		
		// Default voice settings
		let voice = null;
		const voices = window.speechSynthesis.getVoices();
		
		// Try to find the specific voice if provided
		if (voiceId) {
			voice = voices.find(v => v.voiceURI === voiceId);
		}
		
		// If no voice found or specified, use default English voice
		if (!voice) {
			voice = voices.find(v => v.lang.includes('en') && v.default) ||
				   voices.find(v => v.lang.includes('en')) ||
				   voices[0];
		}
		
		if (voice) {
			console.log(\"Speaking text with voice:\", voice.name);
		}
		
		// Create and configure utterance
		const utterance = new SpeechSynthesisUtterance(text);
		if (voice) utterance.voice = voice;
		utterance.lang = 'en-US';
		utterance.rate = rate || 0.8; // Default to slightly slower rate
		utterance.pitch = 1.0;
		
		console.log(\"Speaking text with rate\", utterance.rate + \":\", text);
		
		// Speak the text
		window.speechSynthesis.speak(utterance);
	};
	
	// Save TTS settings
	window.saveTTSSettings = function(voiceId, rate) {
		localStorage.setItem('tts_voice_id', voiceId);
		localStorage.setItem('tts_rate', rate);
		console.log(\"TTS settings saved:\", voiceId, rate);
	};
	
	// JavaScript bridge test function
	window.testJavaScriptBridge = function() {
		console.log(\"JavaScript bridge test function called successfully\");
		return \"JavaScript bridge is working!\";
	};
	
	// ===== IMAGE PROCESSING (VISION API) =====
	// Direct function for Godot to process an image through Google Cloud Vision API
	window.godotProcessImageVision = function(base64Image, width, height) {
		return new Promise(function(resolve, reject) {
			try {
				console.log(\"godotProcessImageVision called with image: \" + width + \"x\" + height);

				// First preprocess the image with timeout handling
				const preprocessPromise = new Promise((resolvePreprocess, rejectPreprocess) => {
					// Set a timeout for preprocessing
					const timeoutId = setTimeout(() => {
						rejectPreprocess(new Error('Preprocessing timed out'));
					}, 5000);

					window.preprocessHandwritingImage(base64Image, width, height)
						.then(function(processedImage) {
							clearTimeout(timeoutId);
							resolvePreprocess(processedImage);
						})
						.catch(function(error) {
							clearTimeout(timeoutId);
							rejectPreprocess(error);
						});
				});
				
				preprocessPromise
					.then(function(processedImage) {
						// Then call the Cloud Vision API with timeout handling
						const apiPromise = new Promise((resolveApi, rejectApi) => {
							// Set a timeout for API call
							const timeoutId = setTimeout(() => {
								rejectApi(new Error('API call timed out'));
							}, 10000);
							
							window.callGoogleVisionApi(processedImage)
								.then(function(result) {
									clearTimeout(timeoutId);
									console.log('Vision API result:', result);
									resolve(result);
								})
								.catch(function(error) {
									clearTimeout(timeoutId);
									console.error('Error in Vision API call:', error);
									resolve('recognition_error: ' + error.message);
								});
						});
						
						return apiPromise;
					})
					.catch(function(error) {
						console.error('Error preprocessing image:', error);
						resolve('recognition_error: ' + error.message);
					});
			} catch(error) {
				console.error('Error in image processing:', error);
				resolve('recognition_error: ' + error.message);
			}
		});
	};

	// Function to preprocess images before sending to Cloud Vision API
	window.preprocessHandwritingImage = function(imageBase64, canvasWidth, canvasHeight) {
		return new Promise((resolve) => {
			try {
				console.log(\"Preprocessing image: \" + canvasWidth + \"x\" + canvasHeight);
				const img = new Image();
				const canvas = document.createElement('canvas');
				const ctx = canvas.getContext('2d');

				// Use a smaller size for the image to reduce data size
				const maxSize = 600; // Reduced from 800
				let width = canvasWidth;
				let height = canvasHeight;

				// Resize if too large
				if (width > maxSize || height > maxSize) {
					const ratio = width / height;
					if (width > height) {
						width = maxSize;
						height = width / ratio;
					} else {
						height = maxSize;
						width = height * ratio;
					}
				}

				canvas.width = width;
				canvas.height = height;

				// Add error handling to image loading
				img.onload = function() {
					// Draw image on white background
					ctx.fillStyle = 'white';
					ctx.fillRect(0, 0, canvas.width, canvas.height);

					// Draw with higher contrast
					ctx.globalAlpha = 1.0; // Full opacity for better contrast
					ctx.drawImage(img, 0, 0, width, height);

					// Process the image to enhance recognition - improved algorithm
					const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
					const data = imageData.data;

					// Enhanced thresholding for handwriting
					for (let i = 0; i < data.length; i += 4) {
						const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
						// Lower threshold for better detection of light strokes
						const value = avg < 140 ? 0 : 255;  // Changed from 160 to 140
						data[i] = data[i + 1] = data[i + 2] = value;
					}

					ctx.putImageData(imageData, 0, 0);

					// Use PNG format which is better for text
					try {
						const pngData = canvas.toDataURL('image/png', 1.0).split(',')[1];
						console.log('Using PNG format for image with maximum quality');
						resolve(pngData);
					} catch (e) {
						console.error('Error converting image:', e);
						resolve(imageBase64); // Fallback to original image
					}
				};

				img.onerror = function(e) {
					console.error('Error loading image:', e);
					resolve(imageBase64); // Fallback to original image
				};

				// Set crossOrigin to anonymous
				img.crossOrigin = 'Anonymous';
				img.src = 'data:image/png;base64,' + imageBase64;
			} catch(e) {
				console.error('Preprocessing error:', e);
				resolve(imageBase64); // Fallback to original image
			}
		});
	};

	// Google Cloud Vision API implementation
	window.callGoogleVisionApi = async function(base64Image) {
		try {
			console.log('Calling Google Cloud Vision API...');

			// Use the configured API key
			const apiKey = window.GOOGLE_CLOUD_API_KEY;
			if (!apiKey) {
				throw new Error(\"API key not found\");
			}

			const url = 'https://vision.googleapis.com/v1/images:annotate?key=' + apiKey;

			// Log image size to help with debugging
			console.log('Image size (bytes):', Math.round(base64Image.length * 0.75));

			// Prepare the request data with simpler features
			const requestData = {
				requests: [{
					image: {
						content: base64Image
					},
					features: [{
						type: 'DOCUMENT_TEXT_DETECTION',
						maxResults: 5
					}],
					imageContext: {
						languageHints: ['en']
					}
				}]
			};

			// Send the request with improved error handling
			console.log('Sending request to Vision API...');
			const response = await fetch(url, {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Accept': 'application/json'
				},
				body: JSON.stringify(requestData)
			});

			console.log('Response status:', response.status);

			if (!response.ok) {
				const errorText = await response.text();
				console.error('API error response:', errorText);
				throw new Error(`API request failed: ${response.status} - ${errorText}`);
			}

			const result = await response.json();
			console.log('Vision API response:', result);

			// Extract text from response - handle both annotation types
			if (result.responses && result.responses[0]) {
				// First try fullTextAnnotation
				if (result.responses[0].fullTextAnnotation) {
					return result.responses[0].fullTextAnnotation.text.trim();
				}
				// Then try textAnnotations
				else if (result.responses[0].textAnnotations && result.responses[0].textAnnotations.length > 0) {
					return result.responses[0].textAnnotations[0].description.trim();
				}
			}

			return 'no_text_detected';
		} catch (error) {
			console.error('Error in Vision API call:', error);
			return 'recognition_error';
		}
	};

	// ===== UNIFIED INITIALIZATION =====
	document.addEventListener('DOMContentLoaded', function() {
		console.log('Initializing web features');
		
		// 1. Initialize speech synthesis
		if ('speechSynthesis' in window) {
			console.log('Initializing speech synthesis');
			
			// Get available voices immediately
			window.speechSynthesis.getVoices();
			
			// Set up voice change event handler
			if (typeof speechSynthesis.onvoiceschanged !== 'undefined') {
				speechSynthesis.onvoiceschanged = function() {
					console.log('Voices loaded:', window.speechSynthesis.getVoices().length);
				};
			}
			
			// Create a silent utterance to initialize the system
			const silence = new SpeechSynthesisUtterance('');
			silence.volume = 0; // Silent
			window.speechSynthesis.speak(silence);
			
			// Set up user interaction handler for browsers that need it
			document.addEventListener('click', function initAudio() {
				if (window.speechSynthesis) {
					const click = new SpeechSynthesisUtterance('.');
					click.volume = 0;
					window.speechSynthesis.speak(click);

					// Only need to do this once
					document.removeEventListener('click', initAudio);
					console.log('Speech synthesis initialized via user interaction');
				}
			});
		}
		
		// 2. Check for existing microphone permissions WITHOUT requesting them
		if (navigator.permissions && navigator.permissions.query) {
			navigator.permissions.query({ name: 'microphone' })
			.then(function(permissionStatus) {
				window.godot_speech.permissionState = permissionStatus.state;
				console.log('Initial microphone permission state:', permissionStatus.state);
				
				// Set up permission change listener
				permissionStatus.onchange = function() {
					window.godot_speech.permissionState = this.state;
					console.log('Microphone permission state changed to:', this.state);
				};
			})
			.catch(function(error) {
				console.error('Error checking microphone permission:', error);
			});
		}
		
		// 3. Setup audio permission request helper - don't automatically request
		window.requestAudioPermission = function() {
			return navigator.mediaDevices.getUserMedia({ audio: true })
				.then(function(stream) {
					// Stop tracks immediately, we just wanted permission
					stream.getTracks().forEach(track => track.stop());
					console.log('Audio permission granted');
					return true;
				})
				.catch(function(err) {
					console.error('Audio permission denied:', err);
					return false;
				});
		};
		
		// 4. Tell Godot when engine is ready (for the godot_speech object)
		window.addEventListener('godot-engine-ready', function() {
			console.log('Notifying Godot the engine is ready');
		});
	});
	
	// Clean up audio resources when page is unloaded
	window.addEventListener('beforeunload', function() {
		if (window.godot_speech && window.godot_speech.audioStream) {
			window.godot_speech.audioStream.getTracks().forEach(track => track.stop());
		}
	});
</script>"
html/canvas_resize_policy=2
html/focus_canvas_on_start=true
html/experimental_virtual_keyboard=false
progressive_web_app/enabled=true
progressive_web_app/ensure_cross_origin_isolation_headers=true
progressive_web_app/offline_page=""
progressive_web_app/display=3
progressive_web_app/orientation=1
progressive_web_app/icon_144x144=""
progressive_web_app/icon_180x180=""
progressive_web_app/icon_512x512=""
progressive_web_app/background_color=Color(0, 0, 0, 1)
");
				const blob = await response.blob();
				
				// Convert to base64
				const reader = new FileReader();
				const base64Promise = new Promise(resolve => {
					reader.onloadend = () => resolve(reader.result.split(',')[1]);
					reader.readAsDataURL(blob);
				});
				const base64Image = await base64Promise;
				
				console.log('Test image loaded, size:', Math.round(base64Image.length / 1024), 'KB');
				
				// Now call the Vision API with the base64 data
				const result = await window.callGoogleVisionApi(base64Image);
				console.log('Test result:', result);
				return 'API test completed with result: ' + result;
			} catch (e) {
				console.error('API test failed:', e);
				return 'API test failed: ' + e.message;
			}
		};

		// Run API test on page load to verify connectivity
		document.addEventListener('DOMContentLoaded', function () {
			// Create debug output div
			var debugOutput = document.createElement('div');
			debugOutput.id = 'debug-output';
			document.body.appendChild(debugOutput);
			
			setTimeout(async function () {
				try {
					window.debugLog(\"Testing Vision API...\");
					const testResult = await window.testVisionAPI();
					window.debugLog('API test result: ' + testResult);
				} catch (error) {
					console.error('API test error:', error);
					window.debugLog('API test error: ' + error.message);
				}
			}, 2000);
		});
	</script>

	<script>
		// Initialize speech synthesis for TTS support
		document.addEventListener('DOMContentLoaded', function () {
			console.log('Initializing speech synthesis');

			if ('speechSynthesis' in window) {
				// Get available voices immediately
				window.speechSynthesis.getVoices();

				// Set up voice change event handler
				if (typeof speechSynthesis.onvoiceschanged !== 'undefined') {
					speechSynthesis.onvoiceschanged = function () {
						console.log('Voices loaded:', window.speechSynthesis.getVoices().length);
					};
				}

				// Create a silent utterance to initialize the system
				const silence = new SpeechSynthesisUtterance('');
				silence.volume = 0; // Silent
				window.speechSynthesis.speak(silence);

				// Set up user interaction handler for browsers that need it
				document.addEventListener('click', function initAudio() {
					if (window.speechSynthesis) {
						const click = new SpeechSynthesisUtterance('.');
						click.volume = 0;
						window.speechSynthesis.speak(click);

						// Only need to do this once
						document.removeEventListener('click', initAudio);
						console.log('Speech synthesis initialized via user interaction');
					}
				});

				console.log('Speech synthesis initialized');
			}
		});
	</script>html/canvas_resize_policy"=2

[preset.1]

name="Windows Desktop"
platform="Windows Desktop"
runnable=true
advanced_options=false
dedicated_server=false
custom_features=""
export_filter="all_resources"
include_filter="*.env"
exclude_filter=""
export_path="StandaloneTest/index.exe"
patches=PackedStringArray()
encryption_include_filters=""
encryption_exclude_filters=""
seed=0
encrypt_pck=false
encrypt_directory=false
script_export_mode=2

[preset.1.options]

custom_template/debug=""
custom_template/release=""
debug/export_console_wrapper=1
binary_format/embed_pck=false
texture_format/s3tc_bptc=true
texture_format/etc2_astc=false
binary_format/architecture="x86_64"
codesign/enable=false
codesign/timestamp=true
codesign/timestamp_server_url=""
codesign/digest_algorithm=1
codesign/description=""
codesign/custom_options=PackedStringArray()
application/modify_resources=true
application/icon=""
application/console_wrapper_icon=""
application/icon_interpolation=4
application/file_version=""
application/product_version=""
application/company_name=""
application/product_name=""
application/file_description=""
application/copyright=""
application/trademarks=""
application/export_angle=0
application/export_d3d12=0
application/d3d12_agility_sdk_multiarch=true
ssh_remote_deploy/enabled=false
ssh_remote_deploy/host="user@host_ip"
ssh_remote_deploy/port="22"
ssh_remote_deploy/extra_args_ssh=""
ssh_remote_deploy/extra_args_scp=""
ssh_remote_deploy/run_script="Expand-Archive -LiteralPath '{temp_dir}\\{archive_name}' -DestinationPath '{temp_dir}'
$action = New-ScheduledTaskAction -Execute '{temp_dir}\\{exe_name}' -Argument '{cmd_args}'
$trigger = New-ScheduledTaskTrigger -Once -At 00:00
$settings = New-ScheduledTaskSettingsSet -AllowStartIfOnBatteries -DontStopIfGoingOnBatteries
$task = New-ScheduledTask -Action $action -Trigger $trigger -Settings $settings
Register-ScheduledTask godot_remote_debug -InputObject $task -Force:$true
Start-ScheduledTask -TaskName godot_remote_debug
while (Get-ScheduledTask -TaskName godot_remote_debug | ? State -eq running) { Start-Sleep -Milliseconds 100 }
Unregister-ScheduledTask -TaskName godot_remote_debug -Confirm:$false -ErrorAction:SilentlyContinue"
ssh_remote_deploy/cleanup_script="Stop-ScheduledTask -TaskName godot_remote_debug -ErrorAction:SilentlyContinue
Unregister-ScheduledTask -TaskName godot_remote_debug -Confirm:$false -ErrorAction:SilentlyContinue
Remove-Item -Recurse -Force '{temp_dir}'"
