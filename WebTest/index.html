<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0">
		<title>Lexia</title>
		<style>
html, body, #canvas {
	margin: 0;
	padding: 0;
	border: 0;
}

body {
	color: white;
	background-color: black;
	overflow: hidden;
	touch-action: none;
}

#canvas {
	display: block;
}

#canvas:focus {
	outline: none;
}

#status, #status-splash, #status-progress {
	position: absolute;
	left: 0;
	right: 0;
}

#status, #status-splash {
	top: 0;
	bottom: 0;
}

#status {
	background-color: #242424;
	display: flex;
	flex-direction: column;
	justify-content: center;
	align-items: center;
	visibility: hidden;
}

#status-splash {
	max-height: 100%;
	max-width: 100%;
	margin: auto;
}

#status-splash.show-image--false {
	display: none;
}

#status-splash.fullsize--true {
	height: 100%;
	width: 100%;
	object-fit: contain;
}

#status-splash.use-filter--false {
	image-rendering: pixelated;
}

#status-progress, #status-notice {
	display: none;
}

#status-progress {
	bottom: 10%;
	width: 50%;
	margin: 0 auto;
}

#status-notice {
	background-color: #5b3943;
	border-radius: 0.5rem;
	border: 1px solid #9b3943;
	color: #e0e0e0;
	font-family: 'Noto Sans', 'Droid Sans', Arial, sans-serif;
	line-height: 1.3;
	margin: 0 2rem;
	overflow: hidden;
	padding: 1rem;
	text-align: center;
	z-index: 1;
}
		</style>
		<link id="-gd-engine-icon" rel="icon" type="image/png" href="index.icon.png" />
<link rel="apple-touch-icon" href="index.apple-touch-icon.png"/>
<link rel="manifest" href="index.manifest.json">
<meta http-equiv="Cross-Origin-Opener-Policy" content="same-origin">
<meta http-equiv="Cross-Origin-Embedder-Policy" content="require-corp">

<script>
	// ===== GLOBAL CONFIGURATION =====
	window.GOOGLE_CLOUD_API_KEY = "AIzaSyCz9BNjDlDYDvioKMwzR2_f8D1vHseQtZ0";
	
	// ===== STATE MANAGEMENT =====
	// Debug and logging functions
	window.debugLog = function(message) {
		console.log("GODOT DEBUG:", message);
		var debugOutput = document.getElementById('debug-output');
		if (debugOutput) {
			debugOutput.style.display = 'block';
			debugOutput.innerText += message + "\n";
			debugOutput.scrollTop = debugOutput.scrollHeight;
		}
		return true;
	};
	
	// Speech recognition state
	window.godot_speech = {
		mediaRecorder: null,
		audioChunks: [],
		audioStream: null,
		recording: false,
		permissionState: 'prompt',
		
		// Debug logging function
		debugLog: function(message) {
			console.log("Speech Debug:", message);
			var debugOutput = document.getElementById('debug-output');
			if (debugOutput) {
				debugOutput.innerText += "Speech: " + message + "\n";
				debugOutput.scrollTop = debugOutput.scrollHeight;
			}
		}
	};
	
	// Challenge word tracking
	window.currentChallengeWord = "";
	window.setChallengeWord = function(word) {
		window.currentChallengeWord = word;
		window.challengeWord = word;  // For compatibility with both versions used
		console.log("Challenge word set to:", word);
		window.debugLog("Challenge word set to: " + word);
	};
	
	// Text-to-Speech functionality
	window.speakText = function(text, voiceId, rate) {
		console.log("Speaking text:", text);
		
		// Default voice settings
		let voice = null;
		const voices = window.speechSynthesis.getVoices();
		
		// Try to find the specific voice if provided
		if (voiceId) {
			voice = voices.find(v => v.voiceURI === voiceId);
		}
		
		// If no voice found or specified, use default English voice
		if (!voice) {
			voice = voices.find(v => v.lang.includes('en') && v.default) ||
				   voices.find(v => v.lang.includes('en')) ||
				   voices[0];
		}
		
		if (voice) {
			console.log("Speaking text with voice:", voice.name);
		}
		
		// Create and configure utterance
		const utterance = new SpeechSynthesisUtterance(text);
		if (voice) utterance.voice = voice;
		utterance.lang = 'en-US';
		utterance.rate = rate || 0.8; // Default to slightly slower rate
		utterance.pitch = 1.0;
		
		console.log("Speaking text with rate", utterance.rate + ":", text);
		
		// Speak the text
		window.speechSynthesis.speak(utterance);
	};
	
	// Save TTS settings
	window.saveTTSSettings = function(voiceId, rate) {
		localStorage.setItem('tts_voice_id', voiceId);
		localStorage.setItem('tts_rate', rate);
		console.log("TTS settings saved:", voiceId, rate);
	};
	
	// JavaScript bridge test function
	window.testJavaScriptBridge = function() {
		console.log("JavaScript bridge test function called successfully");
		return "JavaScript bridge is working!";
	};
	
	// ===== IMAGE PROCESSING (VISION API) =====
	// Direct function for Godot to process an image through Google Cloud Vision API
	window.godotProcessImageVision = function(base64Image, width, height) {
		return new Promise(function(resolve, reject) {
			try {
				console.log("godotProcessImageVision called with image: " + width + "x" + height);

				// First preprocess the image with timeout handling
				const preprocessPromise = new Promise((resolvePreprocess, rejectPreprocess) => {
					// Set a timeout for preprocessing
					const timeoutId = setTimeout(() => {
						rejectPreprocess(new Error('Preprocessing timed out'));
					}, 5000);

					window.preprocessHandwritingImage(base64Image, width, height)
						.then(function(processedImage) {
							clearTimeout(timeoutId);
							resolvePreprocess(processedImage);
						})
						.catch(function(error) {
							clearTimeout(timeoutId);
							rejectPreprocess(error);
						});
				});
				
				preprocessPromise
					.then(function(processedImage) {
						// Then call the Cloud Vision API with timeout handling
						const apiPromise = new Promise((resolveApi, rejectApi) => {
							// Set a timeout for API call
							const timeoutId = setTimeout(() => {
								rejectApi(new Error('API call timed out'));
							}, 10000);
							
							window.callGoogleVisionApi(processedImage)
								.then(function(result) {
									clearTimeout(timeoutId);
									console.log('Vision API result:', result);
									resolve(result);
								})
								.catch(function(error) {
									clearTimeout(timeoutId);
									console.error('Error in Vision API call:', error);
									resolve('recognition_error: ' + error.message);
								});
						});
						
						return apiPromise;
					})
					.catch(function(error) {
						console.error('Error preprocessing image:', error);
						resolve('recognition_error: ' + error.message);
					});
			} catch(error) {
				console.error('Error in image processing:', error);
				resolve('recognition_error: ' + error.message);
			}
		});
	};

	// Function to preprocess images before sending to Cloud Vision API
	window.preprocessHandwritingImage = function(imageBase64, canvasWidth, canvasHeight) {
		return new Promise((resolve) => {
			try {
				console.log("Preprocessing image: " + canvasWidth + "x" + canvasHeight);
				const img = new Image();
				const canvas = document.createElement('canvas');
				const ctx = canvas.getContext('2d');

				// Use a smaller size for the image to reduce data size
				const maxSize = 600; // Reduced from 800
				let width = canvasWidth;
				let height = canvasHeight;

				// Resize if too large
				if (width > maxSize || height > maxSize) {
					const ratio = width / height;
					if (width > height) {
						width = maxSize;
						height = width / ratio;
					} else {
						height = maxSize;
						width = height * ratio;
					}
				}

				canvas.width = width;
				canvas.height = height;

				// Add error handling to image loading
				img.onload = function() {
					// Draw image on white background
					ctx.fillStyle = 'white';
					ctx.fillRect(0, 0, canvas.width, canvas.height);

					// Draw with higher contrast
					ctx.globalAlpha = 1.0; // Full opacity for better contrast
					ctx.drawImage(img, 0, 0, width, height);

					// Process the image to enhance recognition - improved algorithm
					const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
					const data = imageData.data;

					// Enhanced thresholding for handwriting
					for (let i = 0; i < data.length; i += 4) {
						const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
						// Lower threshold for better detection of light strokes
						const value = avg < 140 ? 0 : 255;  // Changed from 160 to 140
						data[i] = data[i + 1] = data[i + 2] = value;
					}

					ctx.putImageData(imageData, 0, 0);

					// Use PNG format which is better for text
					try {
						const pngData = canvas.toDataURL('image/png', 1.0).split(',')[1];
						console.log('Using PNG format for image with maximum quality');
						resolve(pngData);
					} catch (e) {
						console.error('Error converting image:', e);
						resolve(imageBase64); // Fallback to original image
					}
				};

				img.onerror = function(e) {
					console.error('Error loading image:', e);
					resolve(imageBase64); // Fallback to original image
				};

				// Set crossOrigin to anonymous
				img.crossOrigin = 'Anonymous';
				img.src = 'data:image/png;base64,' + imageBase64;
			} catch(e) {
				console.error('Preprocessing error:', e);
				resolve(imageBase64); // Fallback to original image
			}
		});
	};

	// Google Cloud Vision API implementation
	window.callGoogleVisionApi = async function(base64Image) {
		try {
			console.log('Calling Google Cloud Vision API...');

			// Use the configured API key
			const apiKey = window.GOOGLE_CLOUD_API_KEY;
			if (!apiKey) {
				throw new Error("API key not found");
			}

			const url = 'https://vision.googleapis.com/v1/images:annotate?key=' + apiKey;

			// Log image size to help with debugging
			console.log('Image size (bytes):', Math.round(base64Image.length * 0.75));

			// Prepare the request data with simpler features
			const requestData = {
				requests: [{
					image: {
						content: base64Image
					},
					features: [{
						type: 'DOCUMENT_TEXT_DETECTION',
						maxResults: 5
					}],
					imageContext: {
						languageHints: ['en']
					}
				}]
			};

			// Send the request with improved error handling
			console.log('Sending request to Vision API...');
			const response = await fetch(url, {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'Accept': 'application/json'
				},
				body: JSON.stringify(requestData)
			});

			console.log('Response status:', response.status);

			if (!response.ok) {
				const errorText = await response.text();
				console.error('API error response:', errorText);
				throw new Error(`API request failed: ${response.status} - ${errorText}`);
			}

			const result = await response.json();
			console.log('Vision API response:', result);

			// Extract text from response - handle both annotation types
			if (result.responses && result.responses[0]) {
				// First try fullTextAnnotation
				if (result.responses[0].fullTextAnnotation) {
					return result.responses[0].fullTextAnnotation.text.trim();
				}
				// Then try textAnnotations
				else if (result.responses[0].textAnnotations && result.responses[0].textAnnotations.length > 0) {
					return result.responses[0].textAnnotations[0].description.trim();
				}
			}

			return 'no_text_detected';
		} catch (error) {
			console.error('Error in Vision API call:', error);
			return 'recognition_error';
		}
	};

	// ===== UNIFIED INITIALIZATION =====
	document.addEventListener('DOMContentLoaded', function() {
		console.log('Initializing web features');
		
		// 1. Initialize speech synthesis
		if ('speechSynthesis' in window) {
			console.log('Initializing speech synthesis');
			
			// Get available voices immediately
			window.speechSynthesis.getVoices();
			
			// Set up voice change event handler
			if (typeof speechSynthesis.onvoiceschanged !== 'undefined') {
				speechSynthesis.onvoiceschanged = function() {
					console.log('Voices loaded:', window.speechSynthesis.getVoices().length);
				};
			}
			
			// Create a silent utterance to initialize the system
			const silence = new SpeechSynthesisUtterance('');
			silence.volume = 0; // Silent
			window.speechSynthesis.speak(silence);
			
			// Set up user interaction handler for browsers that need it
			document.addEventListener('click', function initAudio() {
				if (window.speechSynthesis) {
					const click = new SpeechSynthesisUtterance('.');
					click.volume = 0;
					window.speechSynthesis.speak(click);

					// Only need to do this once
					document.removeEventListener('click', initAudio);
					console.log('Speech synthesis initialized via user interaction');
				}
			});
		}
		
		// 2. Check for existing microphone permissions WITHOUT requesting them
		if (navigator.permissions && navigator.permissions.query) {
			navigator.permissions.query({ name: 'microphone' })
			.then(function(permissionStatus) {
				window.godot_speech.permissionState = permissionStatus.state;
				console.log('Initial microphone permission state:', permissionStatus.state);
				
				// Set up permission change listener
				permissionStatus.onchange = function() {
					window.godot_speech.permissionState = this.state;
					console.log('Microphone permission state changed to:', this.state);
				};
			})
			.catch(function(error) {
				console.error('Error checking microphone permission:', error);
			});
		}
		
		// 3. Setup audio permission request helper - don't automatically request
		window.requestAudioPermission = function() {
			return navigator.mediaDevices.getUserMedia({ audio: true })
				.then(function(stream) {
					// Stop tracks immediately, we just wanted permission
					stream.getTracks().forEach(track => track.stop());
					console.log('Audio permission granted');
					return true;
				})
				.catch(function(err) {
					console.error('Audio permission denied:', err);
					return false;
				});
		};
		
		// 4. Tell Godot when engine is ready (for the godot_speech object)
		window.addEventListener('godot-engine-ready', function() {
			console.log('Notifying Godot the engine is ready');
		});
	});
	
	// Clean up audio resources when page is unloaded
	window.addEventListener('beforeunload', function() {
		if (window.godot_speech && window.godot_speech.audioStream) {
			window.godot_speech.audioStream.getTracks().forEach(track => track.stop());
		}
	});
</script>
	</head>
	<body>
		<canvas id="canvas">
			Your browser does not support the canvas tag.
		</canvas>

		<noscript>
			Your browser does not support JavaScript.
		</noscript>

		<div id="status">
			<img id="status-splash" class="show-image--true fullsize--true use-filter--true" src="index.png" alt="">
			<progress id="status-progress"></progress>
			<div id="status-notice"></div>
		</div>

		<script src="index.js"></script>
		<script>
const GODOT_CONFIG = {"args":[],"canvasResizePolicy":2,"ensureCrossOriginIsolationHeaders":true,"executable":"index","experimentalVK":false,"fileSizes":{"index.pck":55768256,"index.wasm":52126319},"focusCanvas":true,"gdextensionLibs":[],"serviceWorker":"index.service.worker.js"};
const GODOT_THREADS_ENABLED = false;
const engine = new Engine(GODOT_CONFIG);

(function () {
	const statusOverlay = document.getElementById('status');
	const statusProgress = document.getElementById('status-progress');
	const statusNotice = document.getElementById('status-notice');

	let initializing = true;
	let statusMode = '';

	function setStatusMode(mode) {
		if (statusMode === mode || !initializing) {
			return;
		}
		if (mode === 'hidden') {
			statusOverlay.remove();
			initializing = false;
			return;
		}
		statusOverlay.style.visibility = 'visible';
		statusProgress.style.display = mode === 'progress' ? 'block' : 'none';
		statusNotice.style.display = mode === 'notice' ? 'block' : 'none';
		statusMode = mode;
	}

	function setStatusNotice(text) {
		while (statusNotice.lastChild) {
			statusNotice.removeChild(statusNotice.lastChild);
		}
		const lines = text.split('\n');
		lines.forEach((line) => {
			statusNotice.appendChild(document.createTextNode(line));
			statusNotice.appendChild(document.createElement('br'));
		});
	}

	function displayFailureNotice(err) {
		console.error(err);
		if (err instanceof Error) {
			setStatusNotice(err.message);
		} else if (typeof err === 'string') {
			setStatusNotice(err);
		} else {
			setStatusNotice('An unknown error occurred.');
		}
		setStatusMode('notice');
		initializing = false;
	}

	const missing = Engine.getMissingFeatures({
		threads: GODOT_THREADS_ENABLED,
	});

	if (missing.length !== 0) {
		if (GODOT_CONFIG['serviceWorker'] && GODOT_CONFIG['ensureCrossOriginIsolationHeaders'] && 'serviceWorker' in navigator) {
			let serviceWorkerRegistrationPromise;
			try {
				serviceWorkerRegistrationPromise = navigator.serviceWorker.getRegistration();
			} catch (err) {
				serviceWorkerRegistrationPromise = Promise.reject(new Error('Service worker registration failed.'));
			}
			// There's a chance that installing the service worker would fix the issue
			Promise.race([
				serviceWorkerRegistrationPromise.then((registration) => {
					if (registration != null) {
						return Promise.reject(new Error('Service worker already exists.'));
					}
					return registration;
				}).then(() => engine.installServiceWorker()),
				// For some reason, `getRegistration()` can stall
				new Promise((resolve) => {
					setTimeout(() => resolve(), 2000);
				}),
			]).then(() => {
				// Reload if there was no error.
				window.location.reload();
			}).catch((err) => {
				console.error('Error while registering service worker:', err);
			});
		} else {
			// Display the message as usual
			const missingMsg = 'Error\nThe following features required to run Godot projects on the Web are missing:\n';
			displayFailureNotice(missingMsg + missing.join('\n'));
		}
	} else {
		setStatusMode('progress');
		engine.startGame({
			'onProgress': function (current, total) {
				if (current > 0 && total > 0) {
					statusProgress.value = current;
					statusProgress.max = total;
				} else {
					statusProgress.removeAttribute('value');
					statusProgress.removeAttribute('max');
				}
			},
		}).then(() => {
			setStatusMode('hidden');
		}, displayFailureNotice);
	}
}());
		</script>
	</body>
</html>

